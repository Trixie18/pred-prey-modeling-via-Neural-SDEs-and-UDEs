{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0e41635",
   "metadata": {},
   "source": [
    "Neural SDE on Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db3a1677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "--- Generating Synthetic Lotka-Volterra Data ---\n",
      "Adding Gaussian noise with std dev 0.1 to synthetic data.\n",
      "Applied noise and non-negativity clamp.\n",
      "Generated 200 data points from t=0 to t=10.\n",
      "True LV Parameters: alpha=1.5, beta=1.0, gamma=2.0, delta=0.5\n",
      "Splitting data: 160 training points, 40 test points.\n",
      "Scaling data using StandardScaler (fitted on training data)...\n",
      "Scaler Mean: [4.00458    1.50427472], Scaler Scale: [2.8739644  1.24541893]\n",
      "Data prepared for PyTorch:\n",
      "  Training time shape: torch.Size([160]), Training data shape (scaled): torch.Size([160, 2])\n",
      "  Test time shape (np):(40,), Test data shape (orig): (40, 2)\n",
      "  Initial condition (u0, scaled): [1.4074953 1.1898799]\n"
     ]
    }
   ],
   "source": [
    "# Display the Python code block below\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# --- SDE Import ---\n",
    "try:\n",
    "    import torchsde\n",
    "except ImportError:\n",
    "    print(\"Error: torchsde not found. Please install it: pip install torchsde\")\n",
    "    exit()\n",
    "# --- ODE Solver (Keep for comparison/reference if needed, but not used for SDE) ---\n",
    "from scipy.integrate import odeint as scipy_odeint # For generating synthetic data\n",
    "# Metrics and plotting will be used in later sections\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- 0. Configuration & Setup ---\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Device setup\n",
    "# Check for MPS (Apple Silicon GPU) first, then CUDA, then CPU\n",
    "#if torch.backends.mps.is_available():\n",
    "#    device = torch.device(\"mps\")\n",
    "#elif torch.cuda.is_available():\n",
    "#    device = torch.device(\"cuda\")\n",
    "#else:\n",
    "#    device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "# Hyperparameters for Neural SDE Training (Combining stability focus with user's structure)\n",
    "LEARNING_RATE = 1e-2     # Keep stability-focused LR\n",
    "NUM_EPOCHS = 1000        # Adopted from user code\n",
    "HIDDEN_DIM_NN = 32\n",
    "SDE_SOLVER_METHOD = 'srk'  # Stochastic Runge-Kutta\n",
    "SDE_SOLVER_DT = 1e-2     # Keep stability-focused dt\n",
    "NOISE_TYPE = \"diagonal\"  \n",
    "BROWNIAN_SIZE = 2        # Dimension of Brownian motion (must match state_dim for diagonal)\n",
    "PRINT_EVERY = 10        # Adopted from user code\n",
    "WEIGHT_DECAY = 1e-6\n",
    "GRADIENT_CLIP_MAX_NORM = 1.0 # Max norm for gradient clipping\n",
    "\n",
    "# Noise Option - ADDED from user code\n",
    "ADD_NOISE = True         # Set to False to train on clean data\n",
    "NOISE_LEVEL_SYNTH = 0.10  # Noise magnitude if ADD_NOISE is True\n",
    "\n",
    "# Parameters for Synthetic Data Generation\n",
    "TRUE_ALPHA = 1.5\n",
    "TRUE_BETA = 1.0\n",
    "TRUE_GAMMA = 2.0\n",
    "TRUE_DELTA = 0.5\n",
    "TRUE_PARAMS = [TRUE_ALPHA, TRUE_BETA, TRUE_GAMMA, TRUE_DELTA]\n",
    "U0_SYNTH = [8.0, 3.0]\n",
    "T_START = 0\n",
    "T_END = 10\n",
    "N_POINTS = 200\n",
    "\n",
    "# --- 1a. Generate Synthetic Lotka-Volterra Data ---\n",
    "print(\"\\n--- Generating Synthetic Lotka-Volterra Data ---\")\n",
    "def lotka_volterra(y, t, alpha, beta, gamma, delta):\n",
    "    prey, predator = y\n",
    "    d_prey = alpha * prey - beta * prey * predator\n",
    "    d_predator = delta * prey * predator - gamma * predator\n",
    "    return [d_prey, d_predator]\n",
    "\n",
    "t_synth_np = np.linspace(T_START, T_END, N_POINTS).astype(np.float32) # Full time numpy array\n",
    "synth_solution = scipy_odeint(\n",
    "    lotka_volterra, U0_SYNTH, t_synth_np,\n",
    "    args=(TRUE_ALPHA, TRUE_BETA, TRUE_GAMMA, TRUE_DELTA)\n",
    ")\n",
    "\n",
    "# --- Add Noise to Synthetic Data (Optional - based on user code) ---\n",
    "if ADD_NOISE:\n",
    "    print(f\"Adding Gaussian noise with std dev {NOISE_LEVEL_SYNTH} to synthetic data.\")\n",
    "    noise = np.random.normal(scale=NOISE_LEVEL_SYNTH, size=synth_solution.shape)\n",
    "    noisy_solution = synth_solution + noise\n",
    "    # Clamp to ensure non-negativity and avoid exact zero after adding noise\n",
    "    u_data_np_full = np.maximum(1e-4, noisy_solution).astype(np.float32)\n",
    "    print(\"Applied noise and non-negativity clamp.\")\n",
    "else:\n",
    "    print(\"Using clean synthetic data.\")\n",
    "    u_data_np_full = synth_solution.astype(np.float32) # Full data numpy array\n",
    "\n",
    "print(f\"Generated {N_POINTS} data points from t={T_START} to t={T_END}.\")\n",
    "print(f\"True LV Parameters: alpha={TRUE_ALPHA}, beta={TRUE_BETA}, gamma={TRUE_GAMMA}, delta={TRUE_DELTA}\")\n",
    "\n",
    "# --- 1b. Data Preparation ---\n",
    "# Calculate split point\n",
    "split_ratio = 0.8\n",
    "split_idx = int(split_ratio * N_POINTS)\n",
    "n_train = split_idx\n",
    "n_test = N_POINTS - n_train\n",
    "\n",
    "if n_train < 1 or n_test < 1: print(\"Error: Not enough data for train/test split.\"); exit()\n",
    "print(f\"Splitting data: {n_train} training points, {n_test} test points.\")\n",
    "\n",
    "# Split numpy arrays first (keep original scale for evaluation/plotting)\n",
    "t_train_np = t_synth_np[:split_idx]\n",
    "u_train_np_orig = u_data_np_full[:split_idx, :] # Original scale train data\n",
    "t_test_np = t_synth_np[split_idx:]\n",
    "u_test_np_orig = u_data_np_full[split_idx:, :]   # Original scale test data\n",
    "\n",
    "# --- Data Scaling ---\n",
    "print(\"Scaling data using StandardScaler (fitted on training data)...\")\n",
    "scaler = StandardScaler()\n",
    "# Fit scaler ONLY on training data, then transform train data\n",
    "u_train_np_scaled = scaler.fit_transform(u_train_np_orig)\n",
    "print(f\"Scaler Mean: {scaler.mean_}, Scaler Scale: {scaler.scale_}\")\n",
    "\n",
    "# Convert necessary parts to PyTorch tensors\n",
    "t_train = torch.tensor(t_train_np, dtype=torch.float32).to(device) # Time points for training SDE solve\n",
    "u_train = torch.tensor(u_train_np_scaled, dtype=torch.float32).to(device) # SCALED target for loss calculation\n",
    "t_data = torch.tensor(t_synth_np, dtype=torch.float32).to(device)  # Full time tensor for evaluation solve\n",
    "\n",
    "# Initial condition from the first point of the SCALED training data\n",
    "u0 = u_train[0].clone().detach().to(device) # SCALED initial condition\n",
    "\n",
    "print(\"Data prepared for PyTorch:\")\n",
    "print(f\"  Training time shape: {t_train.shape}, Training data shape (scaled): {u_train.shape}\")\n",
    "print(f\"  Test time shape (np):{t_test_np.shape}, Test data shape (orig): {u_test_np_orig.shape}\")\n",
    "print(f\"  Initial condition (u0, scaled): {u0.cpu().numpy()}\")\n",
    "\n",
    "\n",
    "# --- 2. Define the Neural SDE Structure --- (Operates on SCALED data)\n",
    "\n",
    "# --- 2a. Known Physics Part (Drift) ---\n",
    "class KnownDynamicsDrift(nn.Module):\n",
    "    def __init__(self, initial_params=None):\n",
    "        super().__init__()\n",
    "        if initial_params is None: # Generic positive guesses\n",
    "             initial_params = torch.tensor([0.5, 0.1, 0.5, 0.1], dtype=torch.float32)\n",
    "        self.log_params = nn.Parameter(torch.log(initial_params + 1e-8))\n",
    "\n",
    "    def forward(self, t, u): # u is SCALED and already clamped in SDEDynamics.f\n",
    "        if u.ndim == 1: u = u.unsqueeze(0)\n",
    "        params = torch.exp(self.log_params)\n",
    "        alpha, beta, gamma, delta = params[0], params[1], params[2], params[3]\n",
    "        # Apply dynamics to scaled state\n",
    "        algae_scaled = u[:, 0]\n",
    "        rotifers_scaled = u[:, 1]\n",
    "        d_algae_scaled = alpha * algae_scaled - beta * algae_scaled * rotifers_scaled\n",
    "        d_rotifers_scaled = delta * algae_scaled * rotifers_scaled - gamma * rotifers_scaled\n",
    "        du_dt_scaled = torch.stack([d_algae_scaled, d_rotifers_scaled], dim=1)\n",
    "        return du_dt_scaled\n",
    "\n",
    "# --- 2b. Unknown Part (Neural Network for Drift Correction) ---\n",
    "class NeuralNetworkDrift(nn.Module):\n",
    "    def __init__(self, input_dim=2, hidden_dim=HIDDEN_DIM_NN, output_dim=2):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim), nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "        for m in self.net.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight, gain=nn.init.calculate_gain('tanh'))\n",
    "                if m.bias is not None: nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, u): # u is SCALED and already clamped in SDEDynamics.f\n",
    "         return self.net(u)\n",
    "\n",
    "# --- 2c. Unknown Part (Neural Network for Diffusion) ---\n",
    "class NeuralNetworkDiffusion(nn.Module):\n",
    "    def __init__(self, input_dim=2, hidden_dim=HIDDEN_DIM_NN, output_dim=2): # output_dim unused\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        if NOISE_TYPE == \"diagonal\": final_output_dim = input_dim\n",
    "        elif NOISE_TYPE == \"scalar\": final_output_dim = 1\n",
    "        elif NOISE_TYPE == \"general\": final_output_dim = input_dim * BROWNIAN_SIZE\n",
    "        else: raise ValueError(f\"Unknown noise_type: {NOISE_TYPE}\")\n",
    "        self.final_output_dim = final_output_dim\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim), nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, final_output_dim) # No final activation\n",
    "        )\n",
    "        # Initialize weights\n",
    "        for m in self.net.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                if m != self.net[-1]: # Hidden layers\n",
    "                    nn.init.xavier_uniform_(m.weight, gain=nn.init.calculate_gain('tanh'))\n",
    "                    if m.bias is not None: nn.init.zeros_(m.bias)\n",
    "                else: # Last layer -> small initial diffusion\n",
    "                    nn.init.uniform_(m.weight, a=-0.01, b=0.01)\n",
    "                    if m.bias is not None: nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "    def forward(self, u): # u is SCALED and already clamped in SDEDynamics.g\n",
    "        return self.net(u)\n",
    "\n",
    "# --- 2d. Combined Neural SDE Dynamics ---\n",
    "class SDEDynamics(nn.Module):\n",
    "    sde_type = \"ito\"\n",
    "    noise_type = NOISE_TYPE\n",
    "\n",
    "    def __init__(self, initial_known_params=None):\n",
    "        super().__init__()\n",
    "        self.known_drift = KnownDynamicsDrift(initial_known_params).to(device)\n",
    "        self.nn_drift = NeuralNetworkDrift().to(device)\n",
    "        self.nn_diffusion = NeuralNetworkDiffusion().to(device)\n",
    "\n",
    "    def f(self, t, u): # Drift function (operates on SCALED u)\n",
    "        u_nonneg = torch.relu(u) # Clamp input state >= 0\n",
    "        known = self.known_drift(t, u_nonneg)\n",
    "        nn_drift = self.nn_drift(u_nonneg)\n",
    "        return known + nn_drift\n",
    "\n",
    "    def g(self, t, u): # Diffusion function (operates on SCALED u)\n",
    "        u_nonneg = torch.relu(u) # Clamp input state >= 0\n",
    "        return self.nn_diffusion(u_nonneg)\n",
    "\n",
    "# --- 3. Setup Model, Optimizer, and Loss ---\n",
    "sde_func = SDEDynamics().to(device)\n",
    "parameters = list(sde_func.parameters())\n",
    "optimizer = optim.Adam(parameters, lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "loss_fn = nn.MSELoss() # Loss on SCALED data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d37ea6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Training Neural SDE on Synthetic Data (1000 Epochs) ---\n",
      "Epoch 1/1000, Loss (Scaled): 208.175415\n",
      "Epoch 10/1000, Loss (Scaled): 0.935773\n",
      "Epoch 20/1000, Loss (Scaled): 0.759084\n",
      "Epoch 30/1000, Loss (Scaled): 0.820251\n",
      "Epoch 40/1000, Loss (Scaled): 0.828238\n",
      "Epoch 50/1000, Loss (Scaled): 0.774556\n",
      "Epoch 60/1000, Loss (Scaled): 0.721235\n",
      "Epoch 70/1000, Loss (Scaled): 0.657098\n",
      "Epoch 80/1000, Loss (Scaled): 0.631252\n",
      "Epoch 90/1000, Loss (Scaled): 0.821171\n",
      "Epoch 100/1000, Loss (Scaled): 0.677611\n",
      "Epoch 110/1000, Loss (Scaled): 0.641683\n",
      "Epoch 120/1000, Loss (Scaled): 0.624559\n",
      "Epoch 130/1000, Loss (Scaled): 0.646389\n",
      "Epoch 140/1000, Loss (Scaled): 0.624991\n",
      "Epoch 150/1000, Loss (Scaled): 0.687060\n",
      "Epoch 160/1000, Loss (Scaled): 0.716171\n",
      "Epoch 170/1000, Loss (Scaled): 0.811312\n",
      "Epoch 180/1000, Loss (Scaled): 0.629290\n",
      "Epoch 190/1000, Loss (Scaled): 0.690032\n",
      "Epoch 200/1000, Loss (Scaled): 0.760886\n",
      "Epoch 210/1000, Loss (Scaled): 0.808700\n",
      "Epoch 220/1000, Loss (Scaled): 0.707179\n",
      "Epoch 230/1000, Loss (Scaled): 0.654533\n",
      "Epoch 240/1000, Loss (Scaled): 0.641992\n",
      "Epoch 250/1000, Loss (Scaled): 1.067277\n",
      "Epoch 260/1000, Loss (Scaled): 0.793789\n",
      "Epoch 270/1000, Loss (Scaled): 0.998873\n",
      "Epoch 280/1000, Loss (Scaled): 1.776547\n",
      "Epoch 290/1000, Loss (Scaled): 0.621243\n",
      "Epoch 300/1000, Loss (Scaled): 0.749128\n",
      "Epoch 310/1000, Loss (Scaled): 0.781571\n",
      "Epoch 320/1000, Loss (Scaled): 0.606007\n",
      "Epoch 330/1000, Loss (Scaled): 1.571020\n",
      "Epoch 340/1000, Loss (Scaled): 0.913797\n",
      "Epoch 350/1000, Loss (Scaled): 0.848626\n",
      "Epoch 360/1000, Loss (Scaled): 0.754544\n",
      "Epoch 370/1000, Loss (Scaled): 0.768403\n",
      "Epoch 380/1000, Loss (Scaled): 0.692090\n",
      "Epoch 390/1000, Loss (Scaled): 0.733391\n",
      "Epoch 400/1000, Loss (Scaled): 0.699666\n",
      "Epoch 410/1000, Loss (Scaled): 0.637164\n",
      "Epoch 420/1000, Loss (Scaled): 0.666587\n",
      "Epoch 430/1000, Loss (Scaled): 0.709654\n",
      "Epoch 440/1000, Loss (Scaled): 0.694280\n",
      "Epoch 450/1000, Loss (Scaled): 0.626459\n",
      "Epoch 460/1000, Loss (Scaled): 0.595657\n",
      "Epoch 470/1000, Loss (Scaled): 0.847811\n",
      "Epoch 480/1000, Loss (Scaled): 0.833523\n",
      "Epoch 490/1000, Loss (Scaled): 0.742001\n",
      "Epoch 500/1000, Loss (Scaled): 0.718344\n",
      "Epoch 510/1000, Loss (Scaled): 0.768224\n",
      "Epoch 520/1000, Loss (Scaled): 0.704165\n",
      "Epoch 530/1000, Loss (Scaled): 0.694247\n",
      "Epoch 540/1000, Loss (Scaled): 0.641870\n",
      "Epoch 550/1000, Loss (Scaled): 0.955056\n",
      "Epoch 560/1000, Loss (Scaled): 0.395993\n",
      "Epoch 570/1000, Loss (Scaled): 0.167303\n",
      "Epoch 580/1000, Loss (Scaled): 0.483431\n",
      "Epoch 590/1000, Loss (Scaled): 2.875912\n",
      "Epoch 600/1000, Loss (Scaled): 0.821027\n",
      "Epoch 610/1000, Loss (Scaled): 0.856514\n",
      "Epoch 620/1000, Loss (Scaled): 0.774056\n",
      "Epoch 630/1000, Loss (Scaled): 0.754309\n",
      "Epoch 640/1000, Loss (Scaled): 0.689753\n",
      "Epoch 650/1000, Loss (Scaled): 0.627658\n",
      "Epoch 660/1000, Loss (Scaled): 0.615092\n",
      "Epoch 670/1000, Loss (Scaled): 0.668063\n",
      "Epoch 680/1000, Loss (Scaled): 0.621806\n",
      "Epoch 690/1000, Loss (Scaled): 0.471139\n",
      "Epoch 700/1000, Loss (Scaled): 0.160997\n",
      "Epoch 710/1000, Loss (Scaled): 1.057598\n",
      "Epoch 720/1000, Loss (Scaled): 0.774572\n",
      "Epoch 730/1000, Loss (Scaled): 0.749301\n",
      "Epoch 740/1000, Loss (Scaled): 0.643458\n",
      "Epoch 750/1000, Loss (Scaled): 0.646452\n",
      "Epoch 760/1000, Loss (Scaled): 0.626938\n",
      "Epoch 770/1000, Loss (Scaled): 0.657836\n",
      "Epoch 780/1000, Loss (Scaled): 0.590484\n",
      "Epoch 790/1000, Loss (Scaled): 0.263399\n",
      "Epoch 800/1000, Loss (Scaled): 0.881335\n",
      "Epoch 810/1000, Loss (Scaled): 0.353824\n",
      "Epoch 820/1000, Loss (Scaled): 0.364072\n",
      "Epoch 830/1000, Loss (Scaled): 0.147207\n",
      "Epoch 840/1000, Loss (Scaled): 0.768018\n",
      "Epoch 850/1000, Loss (Scaled): 0.728770\n",
      "Epoch 860/1000, Loss (Scaled): 0.732632\n",
      "Epoch 870/1000, Loss (Scaled): 0.645732\n",
      "Epoch 880/1000, Loss (Scaled): 0.657987\n",
      "Epoch 890/1000, Loss (Scaled): 0.618539\n",
      "Epoch 900/1000, Loss (Scaled): 0.485104\n",
      "Epoch 910/1000, Loss (Scaled): 0.923772\n",
      "Epoch 920/1000, Loss (Scaled): 0.821735\n",
      "Epoch 930/1000, Loss (Scaled): 0.801763\n",
      "Epoch 940/1000, Loss (Scaled): 0.798056\n",
      "Epoch 950/1000, Loss (Scaled): 0.863542\n",
      "Epoch 960/1000, Loss (Scaled): 0.702882\n",
      "Epoch 970/1000, Loss (Scaled): 0.700292\n",
      "Epoch 980/1000, Loss (Scaled): 0.597029\n",
      "Epoch 990/1000, Loss (Scaled): 0.907326\n",
      "Epoch 1000/1000, Loss (Scaled): 0.847332\n",
      "--- Training Complete ---\n",
      "Final Training Loss (Scaled): 0.847332\n",
      "Best Training Loss Achieved (Scaled): 0.087739 at epoch 694\n",
      "Loading best model state for evaluation...\n",
      "Best model state loaded.\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Training Loop ---\n",
    "print(f\"\\n--- Starting Training Neural SDE on Synthetic Data ({NUM_EPOCHS} Epochs) ---\")\n",
    "losses = []\n",
    "min_loss = float('inf')\n",
    "best_model_state = None\n",
    "best_epoch = 0\n",
    "ts_train = t_train # Use training time tensor\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    sde_func.train()\n",
    "    optimizer.zero_grad()\n",
    "    u0_batch = u0.unsqueeze(0) # Scaled initial condition with batch dim\n",
    "\n",
    "    try:\n",
    "        # Solve SDE on training time points\n",
    "        u_pred_train_scaled = torchsde.sdeint(sde_func, u0_batch, ts_train, method=SDE_SOLVER_METHOD, dt=SDE_SOLVER_DT, names={'drift': 'f', 'diffusion': 'g'})\n",
    "        u_pred_train_scaled = u_pred_train_scaled.squeeze(1) # Remove batch dim\n",
    "\n",
    "        if torch.isnan(u_pred_train_scaled).any() or torch.isinf(u_pred_train_scaled).any():\n",
    "            print(f\"Epoch {epoch}: NaN/Inf detected in prediction. Skipping update.\")\n",
    "            if best_model_state:\n",
    "                 try: sde_func.load_state_dict(best_model_state); print(\"  Restored best model state.\")\n",
    "                 except Exception as load_e: print(f\"  Failed to restore best model state: {load_e}\")\n",
    "            else: print(\"  No previous best state to restore.\")\n",
    "            losses.append(float('nan'))\n",
    "            continue\n",
    "\n",
    "        # Loss calculation using SCALED prediction vs SCALED true data (u_train)\n",
    "        loss = loss_fn(u_pred_train_scaled, u_train)\n",
    "\n",
    "        if torch.isnan(loss): print(f\"Error: Loss is NaN at epoch {epoch}. Stopping.\"); break\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(parameters, max_norm=GRADIENT_CLIP_MAX_NORM) # Clipping\n",
    "        optimizer.step()\n",
    "        current_loss = loss.item()\n",
    "        losses.append(current_loss)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during training loop at epoch {epoch}: {e}\")\n",
    "        if best_model_state: # Try restore before breaking\n",
    "            try: sde_func.load_state_dict(best_model_state); print(\"Restored best state before stopping.\")\n",
    "            except Exception as load_e: print(f\"Failed to restore best state after error: {load_e}\")\n",
    "        break\n",
    "\n",
    "    # Logging\n",
    "    if epoch % PRINT_EVERY == 0 or epoch == 1:\n",
    "        if not np.isnan(current_loss):\n",
    "            print(f\"Epoch {epoch}/{NUM_EPOCHS}, Loss (Scaled): {current_loss:.6f}\")\n",
    "            # Optional: Check learned params & diffusion magnitude\n",
    "            with torch.no_grad():\n",
    "                 current_params = torch.exp(sde_func.known_drift.log_params).cpu().numpy()\n",
    "                 # print(f\"  Learned Params (exp): {np.round(current_params, 3)}\")\n",
    "                 g_u0 = sde_func.g(ts_train[0], u0_batch)\n",
    "                 # print(f\"  Diffusion ||g(0, u0)||: {torch.norm(g_u0).item():.4f}\")\n",
    "\n",
    "    # Save best model\n",
    "    if not np.isnan(current_loss) and current_loss < min_loss:\n",
    "        min_loss = current_loss\n",
    "        best_model_state = sde_func.state_dict()\n",
    "        best_epoch = epoch\n",
    "\n",
    "# --- End of Training ---\n",
    "if epoch < NUM_EPOCHS: print(f\"--- Training stopped early at epoch {epoch} ---\")\n",
    "else: print(\"--- Training Complete ---\")\n",
    "\n",
    "if losses and not np.all(np.isnan(losses)): print(f\"Final Training Loss (Scaled): {losses[-1]:.6f}\")\n",
    "if best_model_state:\n",
    "    print(f\"Best Training Loss Achieved (Scaled): {min_loss:.6f} at epoch {best_epoch}\")\n",
    "    print(\"Loading best model state for evaluation...\")\n",
    "    try: sde_func.load_state_dict(best_model_state); print(\"Best model state loaded.\")\n",
    "    except Exception as e: print(f\"Warning: Failed to load best model state: {e}\")\n",
    "else: print(\"Warning: No valid best model state saved.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9038de7a",
   "metadata": {},
   "source": [
    "Orig SDE Synth code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed0e9c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating SDE Model Fit (Train) and Forecast (Test) ---\n",
      "Generating 1000 ensemble predictions using SDE solver...\n",
      "\n",
      "--- Metrics Calculation (Comparing Mean SDE Prediction to Data) ---\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'u_train_np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 106\u001b[0m\n\u001b[1;32m    102\u001b[0m metrics_test \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metrics_calculated:\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;66;03m# Separate true components for easier metric calculation\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m     u_train_prey \u001b[38;5;241m=\u001b[39m u_train_np[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    107\u001b[0m     u_train_predator \u001b[38;5;241m=\u001b[39m u_train_np[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    108\u001b[0m     u_test_prey \u001b[38;5;241m=\u001b[39m u_test_np[:, \u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'u_train_np' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# --- Helper Functions for Metrics (copied from your provided ODE code) ---\n",
    "def nrmse(y_true, y_pred):\n",
    "    \"\"\"Calculate Normalized Root Mean Squared Error (NRMSE) by range.\"\"\"\n",
    "    if y_true.ndim > 1 and y_true.shape[1] > 1: # Cannot calculate range for multi-output directly\n",
    "        # Calculate NRMSE for each dimension separately and average? Or return NaN?\n",
    "        # Let's return NaN for simplicity, as interpretation gets complex.\n",
    "        # You could modify this to return per-dimension NRMSE if needed.\n",
    "        # print(\"Warning: NRMSE calculated per dimension for multi-output.\")\n",
    "        # nrmse_vals = [nrmse(y_true[:, i], y_pred[:, i]) for i in range(y_true.shape[1])]\n",
    "        # return np.nanmean(nrmse_vals)\n",
    "         return np.nan # Simpler: return NaN for multi-output total NRMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    data_range = np.max(y_true) - np.min(y_true)\n",
    "    if data_range < 1e-8: # Avoid division by zero or near-zero range\n",
    "        return np.nan if rmse > 1e-8 else 0.0\n",
    "    return rmse / data_range\n",
    "\n",
    "def smape(y_true, y_pred, epsilon=1e-8):\n",
    "    \"\"\"Calculate Symmetric Mean Absolute Percentage Error (sMAPE).\"\"\"\n",
    "    numerator = np.abs(y_pred - y_true)\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2.0 # The average scale\n",
    "    # Add epsilon to prevent division by zero where both true and pred are zero\n",
    "    ratio = numerator / (denominator + epsilon)\n",
    "    # Need to handle potential NaNs if both y_true and y_pred are exactly 0 + epsilon\n",
    "    # But mean should handle this okay unless *all* values are zero.\n",
    "    return np.mean(ratio) * 100.0 # Return as percentage\n",
    "\n",
    "\n",
    "# --- 5. Evaluation (Fit on Train + Forecast on Test) ---\n",
    "print(\"\\n--- Evaluating SDE Model Fit (Train) and Forecast (Test) ---\")\n",
    "\n",
    "# --- Configuration for Evaluation ---\n",
    "N_ENSEMBLE = 1000 # Number of SDE paths to simulate for evaluation (>= 1)\n",
    "                # Use > 1 for mean/std dev, 1 for single path evaluation.\n",
    "EVAL_SDE_SOLVER_METHOD = SDE_SOLVER_METHOD # Use the same solver as training or specify another\n",
    "EVAL_SDE_SOLVER_DT = SDE_SOLVER_DT         # Use the same dt as training or specify another\n",
    "\n",
    "sde_func.eval() # Set model to evaluation mode\n",
    "\n",
    "with torch.no_grad():\n",
    "    # --- Generate Ensemble Predictions over FULL time span ---\n",
    "    print(f\"Generating {N_ENSEMBLE} ensemble predictions using SDE solver...\")\n",
    "    all_u_pred_full = []\n",
    "\n",
    "    # Prepare initial condition for batch solving if N_ENSEMBLE > 1\n",
    "    if N_ENSEMBLE > 1:\n",
    "        # Repeat u0 N_ENSEMBLE times along a new batch dimension\n",
    "        u0_ensemble = u0.unsqueeze(0).repeat(N_ENSEMBLE, 1) # Shape: (N_ENSEMBLE, state_dim)\n",
    "    else:\n",
    "        u0_ensemble = u0.unsqueeze(0) # Shape: (1, state_dim)\n",
    "\n",
    "    try:\n",
    "        # Use torchsde.sdeint for prediction\n",
    "        # The output shape will be (time, batch, state_dim)\n",
    "        u_pred_ensemble = torchsde.sdeint(\n",
    "            sde_func,\n",
    "            u0_ensemble,\n",
    "            t_data, # Full time tensor\n",
    "            method=EVAL_SDE_SOLVER_METHOD,\n",
    "            dt=EVAL_SDE_SOLVER_DT,\n",
    "            names={'drift': 'f', 'diffusion': 'g'}\n",
    "        ).to(device)\n",
    "\n",
    "        # Check for NaNs/Infs in the ensemble predictions\n",
    "        if torch.isnan(u_pred_ensemble).any() or torch.isinf(u_pred_ensemble).any():\n",
    "            print(\"Error: NaN or Inf detected in SDE predictions during evaluation.\")\n",
    "            # Handle error case - perhaps skip metrics/plotting or try to analyze\n",
    "            metrics_calculated = False\n",
    "            u_pred_full_np = np.full((len(t_data), u0.shape[0]), np.nan) # Placeholder NaN array\n",
    "            u_pred_full_mean = None # Indicate mean calculation failed\n",
    "            u_pred_full_std = None  # Indicate std calculation failed\n",
    "\n",
    "        else:\n",
    "            # --- Calculate Mean and Std Dev of Ensemble ---\n",
    "            # u_pred_ensemble shape: (time, batch, state_dim) -> (N_POINTS, N_ENSEMBLE, 2)\n",
    "            u_pred_full_mean = torch.mean(u_pred_ensemble, dim=1) # Mean over ensemble dim, shape (N_POINTS, 2)\n",
    "            u_pred_full_std = torch.std(u_pred_ensemble, dim=1)   # Std dev over ensemble dim, shape (N_POINTS, 2)\n",
    "\n",
    "            # Convert MEAN prediction to NumPy for metrics and plotting\n",
    "            u_pred_full_np = u_pred_full_mean.cpu().numpy() # Use mean for comparison\n",
    "\n",
    "            # Split the MEAN predictions into train and test portions\n",
    "            u_pred_train_np = u_pred_full_np[:split_idx, :] # Mean prediction on training timespan\n",
    "            u_pred_test_np = u_pred_full_np[split_idx:, :]  # Mean prediction on test timespan\n",
    "\n",
    "            # Also get std dev as numpy if needed for plotting uncertainty\n",
    "            u_pred_std_np = u_pred_full_std.cpu().numpy() if N_ENSEMBLE > 1 else None\n",
    "\n",
    "            metrics_calculated = True # Flag that metrics can be calculated\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during SDE prediction for evaluation: {e}\")\n",
    "        metrics_calculated = False\n",
    "        u_pred_full_np = np.full((len(t_data), u0.shape[0]), np.nan)\n",
    "        u_pred_full_mean = None\n",
    "        u_pred_full_std = None\n",
    "\n",
    "\n",
    "    # --- Calculate Metrics (using MEAN prediction vs True/Noisy Data) ---\n",
    "    print(\"\\n--- Metrics Calculation (Comparing Mean SDE Prediction to Data) ---\")\n",
    "    metrics_train = {}\n",
    "    metrics_test = {}\n",
    "\n",
    "    if metrics_calculated:\n",
    "        # Separate true components for easier metric calculation\n",
    "        u_train_prey = u_train_np[:, 0]\n",
    "        u_train_predator = u_train_np[:, 1]\n",
    "        u_test_prey = u_test_np[:, 0]\n",
    "        u_test_predator = u_test_np[:, 1]\n",
    "\n",
    "        # Separate predicted (mean) components\n",
    "        u_pred_train_prey = u_pred_train_np[:, 0]\n",
    "        u_pred_train_predator = u_pred_train_np[:, 1]\n",
    "        u_pred_test_prey = u_pred_test_np[:, 0]\n",
    "        u_pred_test_predator = u_pred_test_np[:, 1]\n",
    "\n",
    "        # --- Training Set Metrics (Fit) ---\n",
    "        metrics_train['MSE_prey'] = mean_squared_error(u_train_prey, u_pred_train_prey)\n",
    "        metrics_train['MSE_predator'] = mean_squared_error(u_train_predator, u_pred_train_predator)\n",
    "        metrics_train['MSE_total'] = mean_squared_error(u_train_np, u_pred_train_np)\n",
    "        metrics_train['RMSE_prey'] = np.sqrt(metrics_train['MSE_prey'])\n",
    "        metrics_train['RMSE_predator'] = np.sqrt(metrics_train['MSE_predator'])\n",
    "        metrics_train['RMSE_total'] = np.sqrt(metrics_train['MSE_total'])\n",
    "        metrics_train['MAE_prey'] = mean_absolute_error(u_train_prey, u_pred_train_prey)\n",
    "        metrics_train['MAE_predator'] = mean_absolute_error(u_train_predator, u_pred_train_predator)\n",
    "        metrics_train['MAE_total'] = mean_absolute_error(u_train_np, u_pred_train_np)\n",
    "        metrics_train['NRMSE_prey'] = nrmse(u_train_prey, u_pred_train_prey)\n",
    "        metrics_train['NRMSE_predator'] = nrmse(u_train_predator, u_pred_train_predator)\n",
    "        # Total NRMSE calculated per component, averaged, or NaN based on helper function\n",
    "        metrics_train['NRMSE_total'] = nrmse(u_train_np, u_pred_train_np)\n",
    "        metrics_train['sMAPE_prey'] = smape(u_train_prey, u_pred_train_prey)\n",
    "        metrics_train['sMAPE_predator'] = smape(u_train_predator, u_pred_train_predator)\n",
    "        # Total sMAPE is often calculated by averaging component sMAPEs or on flattened arrays\n",
    "        metrics_train['sMAPE_total'] = smape(u_train_np.flatten(), u_pred_train_np.flatten())\n",
    "        metrics_train['R2_prey'] = r2_score(u_train_prey, u_pred_train_prey)\n",
    "        metrics_train['R2_predator'] = r2_score(u_train_predator, u_pred_train_predator)\n",
    "        metrics_train['R2_total'] = r2_score(u_train_np, u_pred_train_np)\n",
    "\n",
    "        # --- Test Set Metrics (Forecast) ---\n",
    "        metrics_test['MSE_prey'] = mean_squared_error(u_test_prey, u_pred_test_prey)\n",
    "        metrics_test['MSE_predator'] = mean_squared_error(u_test_predator, u_pred_test_predator)\n",
    "        metrics_test['MSE_total'] = mean_squared_error(u_test_np, u_pred_test_np)\n",
    "        metrics_test['RMSE_prey'] = np.sqrt(metrics_test['MSE_prey'])\n",
    "        metrics_test['RMSE_predator'] = np.sqrt(metrics_test['MSE_predator'])\n",
    "        metrics_test['RMSE_total'] = np.sqrt(metrics_test['MSE_total'])\n",
    "        metrics_test['MAE_prey'] = mean_absolute_error(u_test_prey, u_pred_test_prey)\n",
    "        metrics_test['MAE_predator'] = mean_absolute_error(u_test_predator, u_pred_test_predator)\n",
    "        metrics_test['MAE_total'] = mean_absolute_error(u_test_np, u_pred_test_np)\n",
    "        metrics_test['NRMSE_prey'] = nrmse(u_test_prey, u_pred_test_prey)\n",
    "        metrics_test['NRMSE_predator'] = nrmse(u_test_predator, u_pred_test_predator)\n",
    "        metrics_test['NRMSE_total'] = nrmse(u_test_np, u_pred_test_np)\n",
    "        metrics_test['sMAPE_prey'] = smape(u_test_prey, u_pred_test_prey)\n",
    "        metrics_test['sMAPE_predator'] = smape(u_test_predator, u_pred_test_predator)\n",
    "        metrics_test['sMAPE_total'] = smape(u_test_np.flatten(), u_pred_test_np.flatten())\n",
    "        metrics_test['R2_prey'] = r2_score(u_test_prey, u_pred_test_prey)\n",
    "        metrics_test['R2_predator'] = r2_score(u_test_predator, u_pred_test_predator)\n",
    "        metrics_test['R2_total'] = r2_score(u_test_np, u_pred_test_np)\n",
    "\n",
    "        # --- Print Metrics ---\n",
    "        print(\"\\n--- Training Set Metrics (Mean SDE Fit vs Data) ---\")\n",
    "        print(f\"  Metric       |   Prey    | Predator  |   Total   \")\n",
    "        print(f\"----------------------------------------------------\")\n",
    "        print(f\"  MSE          | {metrics_train['MSE_prey']:<9.4f} | {metrics_train['MSE_predator']:<9.4f} | {metrics_train['MSE_total']:<9.4f}\")\n",
    "        print(f\"  RMSE         | {metrics_train['RMSE_prey']:<9.4f} | {metrics_train['RMSE_predator']:<9.4f} | {metrics_train['RMSE_total']:<9.4f}\")\n",
    "        print(f\"  MAE          | {metrics_train['MAE_prey']:<9.4f} | {metrics_train['MAE_predator']:<9.4f} | {metrics_train['MAE_total']:<9.4f}\")\n",
    "        print(f\"  NRMSE (range)| {metrics_train['NRMSE_prey']:<9.4f} | {metrics_train['NRMSE_predator']:<9.4f} | {metrics_train['NRMSE_total']:<9.4f}\")\n",
    "        print(f\"  sMAPE (%)    | {metrics_train['sMAPE_prey']:<9.2f} | {metrics_train['sMAPE_predator']:<9.2f} | {metrics_train['sMAPE_total']:<9.2f}\")\n",
    "        print(f\"  R^2          | {metrics_train['R2_prey']:<9.4f} | {metrics_train['R2_predator']:<9.4f} | {metrics_train['R2_total']:<9.4f}\")\n",
    "\n",
    "        print(\"\\n--- Test Set Metrics (Mean SDE Forecast vs Data) ---\")\n",
    "        print(f\"  Metric       |   Prey    | Predator  |   Total   \")\n",
    "        print(f\"----------------------------------------------------\")\n",
    "        print(f\"  MSE          | {metrics_test['MSE_prey']:<9.4f} | {metrics_test['MSE_predator']:<9.4f} | {metrics_test['MSE_total']:<9.4f}\")\n",
    "        print(f\"  RMSE         | {metrics_test['RMSE_prey']:<9.4f} | {metrics_test['RMSE_predator']:<9.4f} | {metrics_test['RMSE_total']:<9.4f}\")\n",
    "        print(f\"  MAE          | {metrics_test['MAE_prey']:<9.4f} | {metrics_test['MAE_predator']:<9.4f} | {metrics_test['MAE_total']:<9.4f}\")\n",
    "        print(f\"  NRMSE (range)| {metrics_test['NRMSE_prey']:<9.4f} | {metrics_test['NRMSE_predator']:<9.4f} | {metrics_test['NRMSE_total']:<9.4f}\")\n",
    "        print(f\"  sMAPE (%)    | {metrics_test['sMAPE_prey']:<9.2f} | {metrics_test['sMAPE_predator']:<9.2f} | {metrics_test['sMAPE_total']:<9.2f}\")\n",
    "        print(f\"  R^2          | {metrics_test['R2_prey']:<9.4f} | {metrics_test['R2_predator']:<9.4f} | {metrics_test['R2_total']:<9.4f}\")\n",
    "        print(\"-\" * 52)\n",
    "\n",
    "    else:\n",
    "        print(\"Metrics calculation skipped due to errors in prediction generation.\")\n",
    "\n",
    "\n",
    "    # --- Learned Parameter Printout (Drift part) ---\n",
    "    try:\n",
    "        # Access parameters from the known_drift submodule of sde_func\n",
    "        learned_log_params = sde_func.known_drift.log_params\n",
    "        learned_params = torch.exp(learned_log_params).cpu().numpy()\n",
    "        print(\"\\nLearned Physical Parameters (Drift) vs True Parameters:\")\n",
    "        print(f\"                 True     Learned\")\n",
    "        # Ensure TRUE_PARAMS are accessible here\n",
    "        print(f\"  alpha:   {TRUE_PARAMS[0]:<8.4f} {learned_params[0]:<8.4f}\")\n",
    "        print(f\"  beta:    {TRUE_PARAMS[1]:<8.4f} {learned_params[1]:<8.4f}\")\n",
    "        print(f\"  gamma:   {TRUE_PARAMS[2]:<8.4f} {learned_params[2]:<8.4f}\")\n",
    "        print(f\"  delta:   {TRUE_PARAMS[3]:<8.4f} {learned_params[3]:<8.4f}\")\n",
    "    except AttributeError:\n",
    "        print(\"\\nCould not retrieve learned drift parameters (check model structure).\")\n",
    "    except NameError:\n",
    "        print(\"\\nCould not retrieve learned drift parameters (TRUE_PARAMS not defined).\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError retrieving learned drift parameters: {e}\")\n",
    "\n",
    "\n",
    "# --- 6. Plotting Results ---\n",
    "print(\"\\n--- Generating Plots (SDE Mean Prediction and Uncertainty) ---\")\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "split_time = t_train_np[-1] # Time where split occurs\n",
    "\n",
    "# Plot 1: Loss Curve\n",
    "# This is typically plotted right after the training loop using the 'losses' list.\n",
    "# Example:\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(range(1, len(losses) + 1), losses) # Assuming 'losses' is available\n",
    "# plt.xlabel(\"Epoch\")\n",
    "# plt.ylabel(\"MSE Loss (Training Data)\")\n",
    "# plt.title(\"Training Loss Curve (SDE Synth)\")\n",
    "# plt.yscale('log') # Keep log scale if loss varies greatly\n",
    "# plt.tight_layout()\n",
    "# plt.show() # Show it separately or save it\n",
    "print(\"Skipping loss curve plot here - assumed plotted after training loop.\")\n",
    "\n",
    "\n",
    "# Plot 2: Time Series Fit and Forecast (Mean Prediction + Uncertainty)\n",
    "fig_ts, axs_ts = plt.subplots(2, 1, figsize=(12, 9), sharex=True) # Increased height slightly\n",
    "\n",
    "if metrics_calculated: # Only plot if predictions were successful\n",
    "    # Define colors\n",
    "    fit_color_prey = 'deepskyblue'\n",
    "    forecast_color_prey = 'blue'\n",
    "    fit_color_predator = 'limegreen'\n",
    "    forecast_color_predator = 'green'\n",
    "    uncertainty_color_prey = 'lightblue'\n",
    "    uncertainty_color_predator = 'lightgreen'\n",
    "\n",
    "    # Data for plotting forecast continuously from end of fit (MEAN prediction)\n",
    "    t_forecast_plot = np.concatenate(([t_train_np[-1]], t_test_np))\n",
    "    u_pred_forecast_plot_prey = np.concatenate(([u_pred_train_np[-1, 0]], u_pred_test_np[:, 0]))\n",
    "    u_pred_forecast_plot_predator = np.concatenate(([u_pred_train_np[-1, 1]], u_pred_test_np[:, 1]))\n",
    "\n",
    "    # --- Prey Subplot ---\n",
    "    # Plot the FIT part of the MEAN prediction\n",
    "    axs_ts[0].plot(t_train_np, u_pred_train_np[:, 0], color=fit_color_prey, linestyle='-', linewidth=2, label='SDE Mean Pred. (Fit)')\n",
    "    # Plot the FORECAST part of the MEAN prediction\n",
    "    axs_ts[0].plot(t_forecast_plot, u_pred_forecast_plot_prey, color=forecast_color_prey, linestyle='-', linewidth=2, label='SDE Mean Pred. (Forecast)')\n",
    "\n",
    "    # Plot Uncertainty Bands (if N_ENSEMBLE > 1)\n",
    "    if N_ENSEMBLE > 1 and u_pred_std_np is not None:\n",
    "        # Split std dev array\n",
    "        u_pred_train_std_np = u_pred_std_np[:split_idx, :]\n",
    "        u_pred_test_std_np = u_pred_std_np[split_idx:, :]\n",
    "        # Combine last train std with test std for continuous forecast band plotting\n",
    "        u_pred_forecast_plot_std_prey = np.concatenate(([u_pred_train_std_np[-1, 0]], u_pred_test_std_np[:, 0]))\n",
    "\n",
    "        # Fit uncertainty\n",
    "        axs_ts[0].fill_between(t_train_np,\n",
    "                               u_pred_train_np[:, 0] - u_pred_train_std_np[:, 0],\n",
    "                               u_pred_train_np[:, 0] + u_pred_train_std_np[:, 0],\n",
    "                               color=uncertainty_color_prey, alpha=0.4, label='Std Dev (Fit)')\n",
    "        # Forecast uncertainty\n",
    "        axs_ts[0].fill_between(t_forecast_plot,\n",
    "                               u_pred_forecast_plot_prey - u_pred_forecast_plot_std_prey,\n",
    "                               u_pred_forecast_plot_prey + u_pred_forecast_plot_std_prey,\n",
    "                               color=uncertainty_color_prey, alpha=0.6, label='Std Dev (Forecast)') # Slightly darker alpha\n",
    "\n",
    "    # Plot data points\n",
    "    axs_ts[0].plot(t_train_np, u_train_np[:, 0], 'ko', markersize=4, alpha=0.7, label='Training Data (Prey)')\n",
    "    axs_ts[0].plot(t_test_np, u_test_np[:, 0], 'ro', markersize=4, alpha=0.7, label='Test Data (Prey)')\n",
    "    axs_ts[0].axvline(split_time, color='gray', linestyle='--', linewidth=1.5, label='Train/Test Split')\n",
    "    axs_ts[0].set_ylabel(\"Prey Population\")\n",
    "    axs_ts[0].legend(loc='upper right', fontsize=9)\n",
    "    axs_ts[0].set_title(f\"SDE Fit & Forecast (Mean of {N_ENSEMBLE} Paths) on Synthetic Data\")\n",
    "\n",
    "    # --- Predator Subplot ---\n",
    "    # Plot the FIT part of the MEAN prediction\n",
    "    axs_ts[1].plot(t_train_np, u_pred_train_np[:, 1], color=fit_color_predator, linestyle='-', linewidth=2, label='SDE Mean Pred. (Fit)')\n",
    "    # Plot the FORECAST part of the MEAN prediction\n",
    "    axs_ts[1].plot(t_forecast_plot, u_pred_forecast_plot_predator, color=forecast_color_predator, linestyle='-', linewidth=2, label='SDE Mean Pred. (Forecast)')\n",
    "\n",
    "    # Plot Uncertainty Bands (if N_ENSEMBLE > 1)\n",
    "    if N_ENSEMBLE > 1 and u_pred_std_np is not None:\n",
    "         # Use split std dev from above\n",
    "         u_pred_forecast_plot_std_predator = np.concatenate(([u_pred_train_std_np[-1, 1]], u_pred_test_std_np[:, 1]))\n",
    "         # Fit uncertainty\n",
    "         axs_ts[1].fill_between(t_train_np,\n",
    "                                u_pred_train_np[:, 1] - u_pred_train_std_np[:, 1],\n",
    "                                u_pred_train_np[:, 1] + u_pred_train_std_np[:, 1],\n",
    "                                color=uncertainty_color_predator, alpha=0.4, label='Std Dev (Fit)')\n",
    "         # Forecast uncertainty\n",
    "         axs_ts[1].fill_between(t_forecast_plot,\n",
    "                                u_pred_forecast_plot_predator - u_pred_forecast_plot_std_predator,\n",
    "                                u_pred_forecast_plot_predator + u_pred_forecast_plot_std_predator,\n",
    "                                color=uncertainty_color_predator, alpha=0.6, label='Std Dev (Forecast)')\n",
    "\n",
    "    # Plot data points\n",
    "    axs_ts[1].plot(t_train_np, u_train_np[:, 1], 'ko', markersize=4, alpha=0.7, label='Training Data (Predator)')\n",
    "    axs_ts[1].plot(t_test_np, u_test_np[:, 1], 'ro', markersize=4, alpha=0.7, label='Test Data (Predator)')\n",
    "    axs_ts[1].axvline(split_time, color='gray', linestyle='--', linewidth=1.5) # Split line only\n",
    "    axs_ts[1].set_ylabel(\"Predator Population\")\n",
    "    axs_ts[1].set_xlabel(\"Time\")\n",
    "    axs_ts[1].legend(loc='upper right', fontsize=9)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.96]) # Adjust top margin for title\n",
    "else:\n",
    "    axs_ts[0].set_title(\"SDE Fit & Forecast - Plotting Skipped Due to Prediction Error\")\n",
    "    axs_ts[0].text(0.5, 0.5, 'Error during prediction generation', horizontalalignment='center', verticalalignment='center', transform=axs_ts[0].transAxes)\n",
    "    axs_ts[1].text(0.5, 0.5, 'Error during prediction generation', horizontalalignment='center', verticalalignment='center', transform=axs_ts[1].transAxes)\n",
    "\n",
    "\n",
    "# Plot 3: Phase Plot (Mean Fit and Forecast)\n",
    "plt.figure(3, figsize=(8, 8))\n",
    "if metrics_calculated: # Only plot if predictions were successful\n",
    "    plt.plot(u_train_np[:, 0], u_train_np[:, 1], 'ko', markersize=5, alpha=0.7, label='Training Data')\n",
    "    plt.plot(u_test_np[:, 0], u_test_np[:, 1], 'ro', markersize=5, alpha=0.7, label='Test Data')\n",
    "    # Plot the full MEAN prediction line\n",
    "    plt.plot(u_pred_full_np[:, 0], u_pred_full_np[:, 1], 'm-', linewidth=2, label=f'SDE Mean Pred. (N={N_ENSEMBLE})')\n",
    "    # Mark start/end points\n",
    "    plt.plot(u0[0].cpu(), u0[1].cpu(), 'kX', markersize=10, label='Start')\n",
    "    plt.plot(u_pred_train_np[-1, 0], u_pred_train_np[-1, 1], 'ms', markersize=8, label='End of Fit / Start of Forecast')\n",
    "    plt.xlabel(\"Prey Population\")\n",
    "    plt.ylabel(\"Predator Population\")\n",
    "    plt.title(f\"Phase Plot: Mean SDE Prediction (N={N_ENSEMBLE}) vs Data\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "else:\n",
    "    plt.title(\"Phase Plot - Plotting Skipped Due to Prediction Error\")\n",
    "    plt.text(0.5, 0.5, 'Error during prediction generation', horizontalalignment='center', verticalalignment='center', transform=plt.gca().transAxes)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# --- 7. Visualize Learned Dynamics (Drift Component) ---\n",
    "print(\"\\n--- Visualizing Learned Drift Dynamics (Based on Mean Trajectory) ---\")\n",
    "\n",
    "# We need the mean prediction as a tensor to evaluate the dynamics\n",
    "if metrics_calculated and u_pred_full_mean is not None:\n",
    "    with torch.no_grad():\n",
    "        # Use u_pred_full_mean tensor (output from mean calculation)\n",
    "        known_dyn_pred = torch.zeros_like(u_pred_full_mean)\n",
    "        nn_dyn_pred = torch.zeros_like(u_pred_full_mean)\n",
    "\n",
    "        # Evaluate dynamics at each point along the MEAN predicted trajectory\n",
    "        for i in range(len(t_data)):\n",
    "            # Use the mean state at time t_i as input\n",
    "            u_i_mean = u_pred_full_mean[i].unsqueeze(0) # Add batch dim\n",
    "            t_i = t_data[i]\n",
    "\n",
    "            # Clamp input for safety, similar to training\n",
    "            u_i_mean_nonneg = torch.relu(u_i_mean)\n",
    "\n",
    "            # Get contributions from the trained SDE model's drift components\n",
    "            # Access sub-modules directly\n",
    "            known_dyn_pred[i] = sde_func.known_drift(t_i, u_i_mean_nonneg).squeeze(0)\n",
    "            nn_dyn_pred[i] = sde_func.nn_drift(u_i_mean_nonneg).squeeze(0) # NN drift correction\n",
    "\n",
    "        known_dyn_np = known_dyn_pred.cpu().numpy()\n",
    "        nn_dyn_np = nn_dyn_pred.cpu().numpy()\n",
    "        total_learned_drift_np = known_dyn_np + nn_dyn_np # This is the learned dU/dt (drift part)\n",
    "\n",
    "    # Plot 4: Dynamics Decomposition (Drift only)\n",
    "    fig_decomp, axs_decomp = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    # Prey Dynamics plot\n",
    "    axs_decomp[0, 0].plot(t_data.cpu().numpy(), known_dyn_np[:, 0], 'c--', label='Known Drift (LV)')\n",
    "    axs_decomp[0, 0].plot(t_data.cpu().numpy(), nn_dyn_np[:, 0], 'm:', label='NN Drift Correction')\n",
    "    axs_decomp[0, 0].plot(t_data.cpu().numpy(), total_learned_drift_np[:, 0], 'b-', alpha=0.7, label='Total Learned Drift (f)')\n",
    "    axs_decomp[0, 0].axvline(split_time, color='gray', linestyle=':', linewidth=1) # Indicate split\n",
    "    axs_decomp[0, 0].set_ylabel(\"Rate of Change (Prey Drift)\")\n",
    "    axs_decomp[0, 0].legend(); axs_decomp[0, 0].set_title(\"Drift Decomposition (Prey)\")\n",
    "    axs_decomp[0, 0].axhline(0, color='gray', linestyle='-', linewidth=0.5); axs_decomp[0, 0].grid(True)\n",
    "    # Predator Dynamics plot\n",
    "    axs_decomp[1, 0].plot(t_data.cpu().numpy(), known_dyn_np[:, 1], 'y--', label='Known Drift (LV)')\n",
    "    axs_decomp[1, 0].plot(t_data.cpu().numpy(), nn_dyn_np[:, 1], 'r:', label='NN Drift Correction')\n",
    "    axs_decomp[1, 0].plot(t_data.cpu().numpy(), total_learned_drift_np[:, 1], 'g-', alpha=0.7, label='Total Learned Drift (f)')\n",
    "    axs_decomp[1, 0].axvline(split_time, color='gray', linestyle=':', linewidth=1)\n",
    "    axs_decomp[1, 0].set_ylabel(\"Rate of Change (Predator Drift)\"); axs_decomp[1, 0].set_xlabel(\"Time\")\n",
    "    axs_decomp[1, 0].legend(); axs_decomp[1, 0].axhline(0, color='gray', linestyle='-', linewidth=0.5); axs_decomp[1, 0].grid(True)\n",
    "    # Contribution of NN Drift Term (Prey)\n",
    "    axs_decomp[0, 1].plot(t_data.cpu().numpy(), nn_dyn_np[:, 0], 'm:', label='NN Drift Correction (Prey)')\n",
    "    axs_decomp[0, 1].axvline(split_time, color='gray', linestyle=':', linewidth=1)\n",
    "    axs_decomp[0, 1].set_ylabel(\"NN Output Value\"); axs_decomp[0, 1].legend(); axs_decomp[0, 1].set_title(\"NN Drift Contribution (Prey)\")\n",
    "    axs_decomp[0, 1].axhline(0, color='gray', linestyle='-', linewidth=0.5); axs_decomp[0, 1].grid(True)\n",
    "    # Contribution of NN Drift Term (Predator)\n",
    "    axs_decomp[1, 1].plot(t_data.cpu().numpy(), nn_dyn_np[:, 1], 'r:', label='NN Drift Correction (Predator)')\n",
    "    axs_decomp[1, 1].axvline(split_time, color='gray', linestyle=':', linewidth=1)\n",
    "    axs_decomp[1, 1].set_ylabel(\"NN Output Value\"); axs_decomp[1, 1].set_xlabel(\"Time\")\n",
    "    axs_decomp[1, 1].legend(); axs_decomp[1, 1].set_title(\"NN Drift Contribution (Predator)\")\n",
    "    axs_decomp[1, 1].axhline(0, color='gray', linestyle='-', linewidth=0.5); axs_decomp[1, 1].grid(True)\n",
    "\n",
    "    plt.suptitle(\"Learned Drift Dynamics Decomposition (SDE Synth - Mean Trajectory)\", y=1.02)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.98])\n",
    "\n",
    "else:\n",
    "     print(\"Skipping dynamics decomposition plot due to prediction errors.\")\n",
    "\n",
    "\n",
    "# Show all generated figures at the end\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n--- Evaluation and Plotting Script Finished ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
